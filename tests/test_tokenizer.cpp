#include <gtest/gtest.h>
#include "../src/compiler/lexer/tokenizer.h"
#include <vector>

class TokenizerTest : public ::testing::Test {
protected:
    void SetUp() override {}
    void TearDown() override {}
    
    std::vector<Token> tokenize(const std::string& source) {
        Tokenizer tokenizer(source);
        return tokenizer.tokenize();
    }
};

// üáπüá∑ T√ºrk√ße Anahtar Kelimeler Testi
TEST_F(TokenizerTest, TurkishKeywords) {
    auto tokens = tokenize("yazdƒ±r eƒüer deƒüi≈üken d√∂ng√º fonksiyon");
    
    ASSERT_EQ(tokens.size(), 6); // 5 keywords + EOF
    
    EXPECT_EQ(tokens[0].type, TokenType::KW_YAZDIR);
    EXPECT_EQ(tokens[0].value, "yazdƒ±r");
    EXPECT_EQ(tokens[0].line, 1);
    
    EXPECT_EQ(tokens[1].type, TokenType::KW_EGER);
    EXPECT_EQ(tokens[1].value, "eƒüer");
    
    EXPECT_EQ(tokens[2].type, TokenType::KW_VAR);
    EXPECT_EQ(tokens[2].value, "deƒüi≈üken");
    
    EXPECT_EQ(tokens[3].type, TokenType::KW_DONGU);
    EXPECT_EQ(tokens[3].value, "d√∂ng√º");
    
    EXPECT_EQ(tokens[4].type, TokenType::KW_FONKSIYON);
    EXPECT_EQ(tokens[4].value, "fonksiyon");
    
    EXPECT_EQ(tokens[5].type, TokenType::END_OF_FILE);
}

// üéØ String ve Sayƒ± Testleri
TEST_F(TokenizerTest, StringAndNumbers) {
    auto tokens = tokenize("yazdƒ±r(\"Merhaba D√ºnya\") sayi = 42");
    
    ASSERT_EQ(tokens.size(), 7);
    
    EXPECT_EQ(tokens[0].type, TokenType::KW_YAZDIR);
    EXPECT_EQ(tokens[1].type, TokenType::LPAREN);
    EXPECT_EQ(tokens[2].type, TokenType::STRING);
    EXPECT_EQ(tokens[2].value, "Merhaba D√ºnya");
    EXPECT_EQ(tokens[3].type, TokenType::RPAREN);
    EXPECT_EQ(tokens[4].type, TokenType::IDENTIFIER);
    EXPECT_EQ(tokens[4].value, "sayi");
    EXPECT_EQ(tokens[5].type, TokenType::EQUAL);
    EXPECT_EQ(tokens[6].type, TokenType::INTEGER);
    EXPECT_EQ(tokens[6].value, "42");
}

// üåç UTF-8 Karakter Testi
TEST_F(TokenizerTest, UTF8Characters) {
    auto tokens = tokenize("deƒüi≈üken mesaj = \"ƒü√º≈üƒ±√∂√ßƒû√ú≈ûƒ∞√ñ√á\"");
    
    ASSERT_EQ(tokens.size(), 5);
    
    EXPECT_EQ(tokens[0].type, TokenType::KW_VAR);
    EXPECT_EQ(tokens[0].value, "deƒüi≈üken");
    
    EXPECT_EQ(tokens[1].type, TokenType::IDENTIFIER);
    EXPECT_EQ(tokens[1].value, "mesaj");
    
    EXPECT_EQ(tokens[3].type, TokenType::STRING);
    EXPECT_EQ(tokens[3].value, "ƒü√º≈üƒ±√∂√ßƒû√ú≈ûƒ∞√ñ√á");
}

// ‚ùå Hata Durumlarƒ± Testi
TEST_F(TokenizerTest, InvalidCharacter) {
    EXPECT_THROW(
        tokenize("yazdƒ±r('single quotes')"),
        GumusException
    );
}

TEST_F(TokenizerTest, UnclosedString) {
    EXPECT_THROW(
        tokenize("yazdƒ±r(\"unclosed string)"),
        GumusException
    );
}

// üî¢ Operat√∂r Testi
TEST_F(TokenizerTest, Operators) {
    auto tokens = tokenize("a + b * c / d == e != f <= g >= h");
    
    // Token deƒüerlerini kontrol et
    std::vector<TokenType> expected_types = {
        TokenType::IDENTIFIER, TokenType::PLUS, TokenType::IDENTIFIER,
        TokenType::MULTIPLY, TokenType::IDENTIFIER, TokenType::DIVIDE,
        TokenType::IDENTIFIER, TokenType::EQUAL_EQUAL, TokenType::IDENTIFIER,
        TokenType::BANG_EQUAL, TokenType::IDENTIFIER, TokenType::LESS_EQUAL,
        TokenType::IDENTIFIER, TokenType::GREATER_EQUAL, TokenType::IDENTIFIER,
        TokenType::END_OF_FILE
    };
    
    ASSERT_EQ(tokens.size(), expected_types.size());
    
    for (size_t i = 0; i < expected_types.size(); i++) {
        EXPECT_EQ(tokens[i].type, expected_types[i]) 
            << "Token at position " << i << " has wrong type";
    }
}

// üìù Template String Testi
TEST_F(TokenizerTest, TemplateStrings) {
    auto tokens = tokenize("yazdƒ±r($\"Merhaba {isim}!\")");
    
    ASSERT_GE(tokens.size(), 6);
    
    EXPECT_EQ(tokens[0].type, TokenType::KW_YAZDIR);
    EXPECT_EQ(tokens[1].type, TokenType::LPAREN);
    
    // Template string par√ßalarƒ±
    EXPECT_EQ(tokens[2].type, TokenType::STRING);
    EXPECT_EQ(tokens[2].value, ""); // Ba≈ülangƒ±√ß bo≈ü string
    
    EXPECT_EQ(tokens[3].type, TokenType::PLUS);
    EXPECT_EQ(tokens[4].type, TokenType::STRING);
    EXPECT_EQ(tokens[4].value, "Merhaba ");
    
    // Deƒüi≈üken ve devamƒ±
    EXPECT_EQ(tokens[5].type, TokenType::PLUS);
}

// üéØ Line ve Column Tracking Testi
TEST_F(TokenizerTest, LineAndColumnTracking) {
    auto tokens = tokenize("yazdƒ±r(\"satƒ±r 1\")\nyazdƒ±r(\"satƒ±r 2\")");
    
    // ƒ∞lk satƒ±r
    EXPECT_EQ(tokens[0].line, 1);
    EXPECT_EQ(tokens[0].column, 1);
    
    // ƒ∞kinci satƒ±r (NEW_LINE token'ƒ±)
    EXPECT_EQ(tokens[4].line, 1);
    EXPECT_EQ(tokens[5].line, 2);
    EXPECT_EQ(tokens[5].column, 1);
}

// üîç Escape Sequences Testi
TEST_F(TokenizerTest, EscapeSequences) {
    auto tokens = tokenize("yazdƒ±r(\"Merhaba\\nD√ºnya\\t!\")");
    
    ASSERT_EQ(tokens.size(), 4);
    
    EXPECT_EQ(tokens[2].type, TokenType::STRING);
    EXPECT_EQ(tokens[2].value, "Merhaba\nD√ºnya\t!");
}

// üö´ Edge Case Testleri
TEST_F(TokenizerTest, EmptySource) {
    auto tokens = tokenize("");
    
    ASSERT_EQ(tokens.size(), 1);
    EXPECT_EQ(tokens[0].type, TokenType::END_OF_FILE);
}

TEST_F(TokenizerTest, WhitespaceOnly) {
    auto tokens = tokenize("   \n\t  \n  ");
    
    ASSERT_EQ(tokens.size(), 1);
    EXPECT_EQ(tokens[0].type, TokenType::END_OF_FILE);
}

TEST_F(TokenizerTest, IdentifiersWithNumbers) {
    auto tokens = tokenize("degisken123 _private __magic");
    
    ASSERT_EQ(tokens.size(), 4);
    
    EXPECT_EQ(tokens[0].type, TokenType::IDENTIFIER);
    EXPECT_EQ(tokens[0].value, "degisken123");
    
    EXPECT_EQ(tokens[1].type, TokenType::IDENTIFIER);
    EXPECT_EQ(tokens[1].value, "_private");
    
    EXPECT_EQ(tokens[2].type, TokenType::IDENTIFIER);
    EXPECT_EQ(tokens[2].value, "__magic");
}

// üß™ Main Test Runner
int main(int argc, char **argv) {
    ::testing::InitGoogleTest(&argc, argv);
    return RUN_ALL_TESTS();
}
